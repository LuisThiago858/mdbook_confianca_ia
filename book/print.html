<!DOCTYPE HTML>
<html lang="pt-BR" class="ayu sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>A confiança dos usuários em Sistemas de IA</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "ayu";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('ayu')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">A confiança dos usuários em Sistemas de IA</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introdução-e-contextualização-teórica"><a class="header" href="#introdução-e-contextualização-teórica">Introdução e Contextualização Teórica</a></h1>
<p>A Inteligência Artificial (IA) tornou-se uma força transformadora no cotidiano, presente em setores como saúde, transporte e educação. Originada na década de 1950, a IA evoluiu de sistemas básicos para complexos assistentes e agentes autônomos que influenciam diretamente a agência humana e a tomada de decisões (AFROOGH et al., 2024). Embora promova eficiência e inovação, essa expansão tecnológica levanta novas e significativas questões éticas e sociais.</p>
<p>Apesar de seus benefícios, a aceitação da IA é dificultada pela desconfiança dos usuários. Preocupações com privacidade, discriminação algorítmica e a perda de autonomia humana afetam negativamente a confiança (SARGENT et al., 2024). O uso indevido de dados, a falta de transparência em decisões automatizadas e a disseminação de vieses reforçam essa desconfiança generalizada (BACH et al., 2024). Um relatório da UNESCO também alerta que, sem uma governança ética, a IA pode aprofundar desigualdades e ameaçar direitos humanos fundamentais (UNESCO, 2021).</p>
<p>A complexidade e a opacidade dos sistemas de IA, juntamente com sua capacidade de aprendizado autônomo, dificultam a previsão e a compreensão de seu comportamento, agravando a desconfiança (BACH et al., 2024). A confiança em sistemas de IA depende da correta interpretação de sinais como explicações claras e interações transparentes. A falta desses elementos pode levar a julgamentos equivocados e ao uso inadequado da tecnologia (LIAO; SUNDAR, 2022).</p>
<p>Para construir confiança, é essencial adotar um design ético e centrado no ser humano, incorporando princípios como transparência, justiça, responsabilidade e explicabilidade (KIESLICH; KELLER; STARKE, 2022). A percepção pública apoia a aplicação equilibrada desses princípios, mesmo que existam compromissos técnicos, como o trade-off entre explicabilidade e precisão. Iniciativas globais, como a Recomendação da UNESCO (2021), reforçam a necessidade de um desenvolvimento tecnológico que respeite a dignidade humana e a equidade social.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="justificativa"><a class="header" href="#justificativa">Justificativa</a></h1>
<p>O avanço da Inteligência Artificial (IA) levanta preocupações sobre privacidade, vieses e perda de controle humano, especialmente com a popularização de modelos generativos, o que afeta diretamente a confiança dos usuários (Sargent et al., 2024). A confiança é um elemento central para a adoção responsável da IA e é influenciada por uma combinação de fatores técnicos, socioéticos e características individuais dos usuários, indo além do mero desempenho do sistema (BACH et al., 2024).</p>
<p>A natureza de "caixa-preta" de muitos sistemas de IA compromete a capacidade dos usuários de compreender e avaliar seus resultados (BACH et al., 2024; LIAO; SUNDAR, 2022). Por isso, é crucial que o design dos sistemas de IA inclua "pistas de confiabilidade" para ajudar os usuários a formar julgamentos adequados, evitando tanto a confiança excessiva quanto a desconfiança infundada (LIAO; SUNDAR, 2022). A adoção de princípios éticos explícitos, como transparência, justiça e responsabilidade, é fundamental, conforme reforçam a UNESCO (2021) e estudos que mostram a valorização pública desses múltiplos critérios éticos (KIESLICH; KELLER; STARKE, 2022).</p>
<p>Este estudo foca em usuários não especialistas, que interagem com a IA no dia a dia e, por não terem conhecimento técnico aprofundado, dependem de sinais indiretos para formar sua confiança (BACH et al., 2024; LIAO; SUNDAR, 2022). A construção de sistemas confiáveis exige uma abordagem que abranja todo o ciclo de vida da tecnologia, desde a coleta de dados até o monitoramento contínuo, integrando robustez, explicabilidade, justiça e privacidade em todas as fases (Li et al., 2022).</p>
<p>Como destacam Li et al. (2022), uma falha em qualquer etapa pode comprometer a confiança no sistema inteiro, o que reforça a importância de práticas interdisciplinares e avaliação contínua. Portanto, investigar a percepção desses usuários é crucial para desenvolver um design de IA ético, centrado no humano e alinhado às expectativas da sociedade.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="objetivos"><a class="header" href="#objetivos">Objetivos</a></h1>
<h2 id="objetivo-geral"><a class="header" href="#objetivo-geral">Objetivo Geral</a></h2>
<p>Investigar os fatores que influenciam a confiança dos usuários em sistemas baseados em Inteligência Artificial, analisando suas percepções, experiências e expectativas em relação à transparência, explicabilidade, responsabilidade e outros princípios éticos aplicados ao design de sistemas.</p>
<h2 id="objetivos-específicos"><a class="header" href="#objetivos-específicos">Objetivos Específicos</a></h2>
<ul>
<li>Mapear as principais definições e dimensões da confiança em sistemas de IA, considerando aspectos técnicos, socioéticos e características dos usuários, conforme identificado em estudos recentes (BACH et al., 2024).</li>
<li>Analisar como fatores externos, como preocupações éticas, riscos percebidos e exposição midiática, afetam a formação da confiança dos usuários (SARGENT et al., 2024).</li>
<li>Investigar o impacto da opacidade e da falta de explicabilidade dos sistemas de IA na percepção de confiança dos usuários (BACH et al., 2024; LIAO; SUNDAR, 2022).</li>
<li>Explorar o papel das estratégias de comunicação e design na construção de sinais de confiabilidade percebida, como proposto no modelo MATCH (LIAO; SUNDAR, 2022).</li>
<li>Propor diretrizes para o design ético e centrado no humano de sistemas de IA, fundamentadas nos princípios de transparência, responsabilidade, justiça e inclusão destacados pela UNESCO (2021) e por Kieslich, Keller e Starke (2022).</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="análise-da-confiança-dos-usuários-em-sistemas-baseados-em-inteligência-artificial-ia"><a class="header" href="#análise-da-confiança-dos-usuários-em-sistemas-baseados-em-inteligência-artificial-ia">Análise da Confiança dos Usuários em Sistemas Baseados em Inteligência Artificial (IA)</a></h1>
<h2 id="introdução"><a class="header" href="#introdução">Introdução</a></h2>
<p>A crescente integração dos sistemas baseados em Inteligência Artificial (IA) no cotidiano dos usuários trouxe à tona desafios importantes relacionados à confiança e à percepção desses sistemas. Com base em um questionário estruturado, a pesquisa teve como objetivo compreender a forma como estudantes de áreas não relacionadas diretamente à computação percebem e avaliam a confiança em sistemas como assistentes virtuais, tradutores automáticos e sistemas de recomendação, visando propor melhorias no design e comunicação desses sistemas para torná-los mais éticos e transparentes.</p>
<h2 id="perfil-dos-respondentes"><a class="header" href="#perfil-dos-respondentes">Perfil dos Respondentes</a></h2>
<p>Os respondentes da pesquisa são estudantes universitários que não estão vinculados diretamente à área de tecnologia. Informações demográficas, como idade, curso e período acadêmico, forneceram um contexto necessário para compreender melhor o perfil dos usuários e como suas percepções podem variar com diferentes níveis de maturidade acadêmica e experiências de vida.</p>
<h2 id="uso-de-tecnologias-baseadas-em-ia"><a class="header" href="#uso-de-tecnologias-baseadas-em-ia">Uso de Tecnologias Baseadas em IA</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Tecnologia</th><th>Quantidade</th><th>Porcentagem</th></tr></thead><tbody>
<tr><td>Assistentes virtuais (Alexa, Siri, Google Assistente)</td><td>01</td><td>5,0%</td></tr>
<tr><td>Chatbots de atendimento (bancos, e-commerce)</td><td>05</td><td>25,0%</td></tr>
<tr><td>Sistemas de recomendação (Netflix, Spotify, YouTube)</td><td>02</td><td>10,0%</td></tr>
<tr><td>Tradutores automáticos (Google Tradutor, DeepL)</td><td>05</td><td>25,0%</td></tr>
<tr><td>ChatGPT ou similares</td><td>07</td><td>35,0%</td></tr>
</tbody></table>
</div>
<p><strong>Total de respostas</strong>: 20<br />
<strong>Análise</strong>: A tecnologia mais utilizada foi o ChatGPT, seguida de chatbots e tradutores. Apesar de populares, assistentes virtuais ainda parecem ter uso mais pontual entre os participantes.</p>
<h2 id="percepções-e-confiança"><a class="header" href="#percepções-e-confiança">Percepções e Confiança</a></h2>
<h3 id="fatores-que-aumentam-a-confiança"><a class="header" href="#fatores-que-aumentam-a-confiança">Fatores que Aumentam a Confiança</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Fatores Influenciadores</th><th>Quantidade</th><th>Porcentagem</th></tr></thead><tbody>
<tr><td>Clareza nas respostas ou ações do sistema</td><td>03</td><td>13,6%</td></tr>
<tr><td>Aparência profissional do sistema</td><td>10</td><td>45,5%</td></tr>
<tr><td>Reputação da empresa desenvolvedora</td><td>06</td><td>27,3%</td></tr>
<tr><td>Experiências anteriores positivas</td><td>01</td><td>4,5%</td></tr>
</tbody></table>
</div>
<p><strong>Total de respostas</strong>: 20<br />
<strong>Análise</strong>: A aparência e a reputação são fatores dominantes. A clareza técnica ainda é relevante, mas não foi percebida por todos os respondentes como diferencial de confiança.</p>
<h3 id="fatores-de-diminuição-da-confiança"><a class="header" href="#fatores-de-diminuição-da-confiança">Fatores de Diminuição da Confiança</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Fatores de Diminuição da Confiança</th><th>Quantidade</th><th>Porcentagem</th></tr></thead><tbody>
<tr><td>Falta de controle humano</td><td>15</td><td>75,0%</td></tr>
<tr><td>Dificuldade técnica do sistema</td><td>05</td><td>25,0%</td></tr>
</tbody></table>
</div>
<p><strong>Total de respostas</strong>: 20<br />
<strong>Análise</strong>: A ausência de supervisão humana foi amplamente percebida como fator de desconfiança. A instabilidade técnica aparece como barreira adicional, mas secundária.</p>
<h3 id="características-essenciais-para-confiabilidade"><a class="header" href="#características-essenciais-para-confiabilidade">Características Essenciais para Confiabilidade</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Características Essenciais</th><th>Quantidade</th><th>Porcentagem</th></tr></thead><tbody>
<tr><td>Capacidade de explicar como chegou à resposta</td><td>09</td><td>45,0%</td></tr>
<tr><td>Proteção de dados pessoais e privacidade</td><td>02</td><td>10,0%</td></tr>
<tr><td>Supervisão ou possibilidade de controle humano</td><td>07</td><td>35,0%</td></tr>
<tr><td>Atuação justa e imparcial</td><td>02</td><td>10,0%</td></tr>
</tbody></table>
</div>
<p><strong>Total de respostas</strong>: 20<br />
<strong>Análise</strong>: A maior parte dos participantes valorizou a explicabilidade. Controle e justiça foram relevantes, mas ainda pouco destacados. A privacidade aparece com baixa frequência.</p>
<h2 id="experiências-negativas"><a class="header" href="#experiências-negativas">Experiências Negativas</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Tipos de Problemas</th><th>Quantidade</th><th>Porcentagem</th></tr></thead><tbody>
<tr><td>Privacidade e segurança de dados</td><td>04</td><td>20,0%</td></tr>
<tr><td>Falha no reconhecimento de voz</td><td>06</td><td>30,0%</td></tr>
<tr><td>Imprecisões em respostas fornecidas</td><td>10</td><td>50,0%</td></tr>
</tbody></table>
</div>
<p><strong>Total de respostas</strong>: 20<br />
<strong>Análise</strong>: Os maiores problemas relatados foram erros de resposta e imprecisão. A segurança de dados ainda preocupa, mas apareceu em menos da metade das ocorrências negativas.</p>
<h2 id="compreensão-Ética-e-expectativas"><a class="header" href="#compreensão-Ética-e-expectativas">Compreensão Ética e Expectativas</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Percepção Ética</th><th>Quantidade</th><th>Porcentagem</th></tr></thead><tbody>
<tr><td>Não sabe opinar</td><td>07</td><td>35,0%</td></tr>
<tr><td>Acredita em riscos éticos</td><td>13</td><td>65,0%</td></tr>
</tbody></table>
</div>
<p><strong>Total de respostas</strong>: 20<br />
<strong>Análise</strong>: A maioria reconhece riscos éticos nos sistemas de IA, embora uma parcela relevante ainda demonstre incerteza quanto a essas implicações.</p>
<p>Os participantes enfatizaram a importância da <strong>transparência</strong> como um dos principais elementos para aumentar a confiabilidade, mencionando que gostariam que sistemas ideais fornecessem informações claras sobre as fontes dos dados usados para gerar suas respostas.</p>
<h2 id="considerações-finais"><a class="header" href="#considerações-finais">Considerações Finais</a></h2>
<p>A análise evidencia que a confiança dos usuários em sistemas baseados em IA é influenciada por uma combinação complexa de fatores técnicos, éticos e sociais. Sistemas que apresentam maior clareza, controle humano e transparência tendem a ser percebidos como mais confiáveis, sugerindo que esses são aspectos críticos para o design ético de tecnologias de IA. Recomenda-se que futuras abordagens considerem esses fatores cuidadosamente, promovendo um uso mais seguro, transparente e responsável da IA no cotidiano dos usuários.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="metodologia"><a class="header" href="#metodologia">Metodologia</a></h1>
<p>Este é um <strong>estudo exploratório qualitativo</strong> com duas técnicas de coleta:</p>
<ul>
<li><strong>Entrevistas semiestruturadas</strong></li>
<li><strong>Questionários (abertos e fechados)</strong></li>
</ul>
<h3 id="participantes"><a class="header" href="#participantes">Participantes</a></h3>
<p>Estudantes de graduação <strong>fora da área de computação</strong> que utilizam alguma ferramenta de IA.</p>
<h3 id="análise-de-dados"><a class="header" href="#análise-de-dados">Análise de Dados</a></h3>
<p>Empregou-se <strong>análise de conteúdo temática</strong> baseada em dimensões de confiança já consolidadas na literatura.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cronograma-da-pesquisa"><a class="header" href="#cronograma-da-pesquisa">Cronograma da Pesquisa</a></h1>
<div class="table-wrapper"><table><thead><tr><th>Etapa</th><th>Período</th></tr></thead><tbody>
<tr><td>Revisão bibliográfica</td><td>Maio – Junho</td></tr>
<tr><td>Elaboração dos instrumentos</td><td>Junho</td></tr>
<tr><td>Aplicação dos questionários</td><td>Junho – Julho</td></tr>
<tr><td>Análise qualitativa</td><td>Julho</td></tr>
<tr><td>Sistematização dos resultados</td><td>Julho</td></tr>
<tr><td>Redação final e publicação</td><td>Julho</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="resultados-da-pesquisa"><a class="header" href="#resultados-da-pesquisa">Resultados da Pesquisa</a></h1>
<p>Este capítulo apresenta os principais achados do questionário aplicado com estudantes universitários não pertencentes à área de computação, destacando padrões de uso, percepções e fatores que influenciam a confiança em sistemas de Inteligência Artificial (IA).</p>
<h2 id="uso-de-tecnologias-de-ia"><a class="header" href="#uso-de-tecnologias-de-ia">Uso de Tecnologias de IA</a></h2>
<p>A maioria dos participantes relatou utilizar tecnologias de IA com frequência, especialmente sistemas como <strong>ChatGPT (35%)</strong>, <strong>chatbots de atendimento (25%)</strong> e <strong>tradutores automáticos (25%)</strong>. Isso indica uma integração consistente dessas ferramentas no cotidiano, ainda que assistentes virtuais tenham sido pouco citados (5%).</p>
<h2 id="fatores-que-aumentam-a-confiança-1"><a class="header" href="#fatores-que-aumentam-a-confiança-1">Fatores que Aumentam a Confiança</a></h2>
<p>Os fatores mais relevantes para o aumento da confiança foram:</p>
<ul>
<li><strong>Aparência profissional do sistema (45,5%)</strong></li>
<li><strong>Reputação da empresa desenvolvedora (27,3%)</strong></li>
<li><strong>Clareza nas respostas (13,6%)</strong></li>
</ul>
<p>Esses resultados reforçam a importância da comunicação visual e da credibilidade da marca para gerar segurança no uso de tecnologias automatizadas.</p>
<h2 id="fatores-que-diminuem-a-confiança"><a class="header" href="#fatores-que-diminuem-a-confiança">Fatores que Diminuem a Confiança</a></h2>
<ul>
<li><strong>Falta de controle humano (75%)</strong></li>
<li><strong>Dificuldade técnica (25%)</strong></li>
</ul>
<p>A ausência de supervisão ou capacidade de intervenção por humanos gera desconforto e desconfiança significativa.</p>
<h2 id="características-essenciais-para-confiabilidade-1"><a class="header" href="#características-essenciais-para-confiabilidade-1">Características Essenciais para Confiabilidade</a></h2>
<p>Participantes apontaram como mais importantes:</p>
<ul>
<li><strong>Explicabilidade das respostas (45%)</strong></li>
<li><strong>Supervisão humana (35%)</strong></li>
<li><strong>Privacidade de dados e justiça (10% cada)</strong></li>
</ul>
<p>A explicação clara das decisões tomadas por sistemas de IA foi o critério mais valorizado.</p>
<h2 id="experiências-negativas-1"><a class="header" href="#experiências-negativas-1">Experiências Negativas</a></h2>
<p>Foram citados principalmente:</p>
<ul>
<li><strong>Imprecisões nas respostas (50%)</strong></li>
<li><strong>Falhas de reconhecimento de voz (30%)</strong></li>
<li><strong>Preocupações com segurança de dados (20%)</strong></li>
</ul>
<p>Essas experiências afetam diretamente a disposição dos usuários em utilizar ou confiar novamente em soluções baseadas em IA.</p>
<h2 id="questões-Éticas-e-expectativas"><a class="header" href="#questões-Éticas-e-expectativas">Questões Éticas e Expectativas</a></h2>
<p>A maioria dos participantes (65%) acredita que existem riscos éticos significativos no uso de IA, como decisões enviesadas ou injustas. No entanto, 35% ainda não souberam opinar sobre essas questões, revelando uma lacuna de compreensão que pode ser abordada com educação digital e transparência tecnológica.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="referências"><a class="header" href="#referências">Referências</a></h1>
<p>AFROOGH, Saleh; AKBARI, Ali; MALONE, Emmie; KARGAR, Mohammadali; ALAMBEIGI, Hananeh. Trust in AI: progress, challenges, and future directions. Humanities and Social Sciences Communications, v. 11, 2024. DOI: 10.1057/s41599-024-04044-8.</p>
<p>BACH, Tita Alissa; KHAN, Amna; HALLOCK, Harry; BELTRÃO, Gabriela; SOUSA, Sonia. A Systematic Literature Review of User Trust in AI-Enabled Systems: An HCI Perspective. International Journal of Human–Computer Interaction, v. 40, n. 5, p. 1251–1266, 2024. DOI: 10.1080/10447318.2022.2138826.</p>
<p>KIESLICH, Kimon; KELLER, Birte; STARKE, Christopher. Artificial intelligence ethics by design: Evaluating public perception on the importance of ethical design principles of artificial intelligence. Big Data &amp; Society, 2022. DOI: 10.1177/20539517221092956.</p>
<p>LIAO, Q. Vera; SUNDAR, S. Shyam. Designing for Responsible Trust in AI Systems: A Communication Perspective. In: Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT '22). ACM, 2022. DOI: 10.1145/3531146.3533182.</p>
<p>LI, Bo; QI, Peng; LIU, Bo; DI, Shuai; LIU, Jingen; PEI, Jiquan; YI, Jinfeng; ZHOU, Bowen. Trustworthy AI: From Principles to Practices. ACM Computing Surveys, 2022. Disponível em: https://arxiv.org/abs/2110.01167. Acesso em: 27 abr. 2025.</p>
<p>SARGENT, Carol Springer; KOOHANG, Alex; FLOYD, Kevin; KILBURN, Richard. Artificial Intelligence: Ethical concerns, trust, and risk. Issues in Information Systems, v. 25, n. 2, p. 71-83, 2024. DOI: 10.48009/2_iis_2024_106.</p>
<p>UNESCO. Recomendação sobre a Ética da Inteligência Artificial. Paris: UNESCO, 2021. Disponível em: https://unesdoc.unesco.org/ark:/48223/pf0000381137_por.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
